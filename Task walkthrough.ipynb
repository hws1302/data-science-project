{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff56826e",
   "metadata": {},
   "source": [
    "# CHARA Telescope \n",
    "\n",
    "This project made up 10% of my part II physics course - it was my first time using data science techniques; which were motivated from first principles. The positions of the telescopes relative to each other in the CHARA array are found with star measurement data in what amounts to linear regression. This notebook is meant as a brief introduction to the aims of the project, for more indepth explanations/code look at `projectE-hs723.pdf` or `scripts.py` in the repo. Basic knowledge of NumPy, Pandas and Matplotlib is assumed. \n",
    "\n",
    "<img src=\"https://www.chara.gsu.edu/files/images/chara_overview_figure.png\"  width=\"500\">\n",
    "\n",
    "\n",
    "## What is the problem\n",
    "\n",
    "### Why should we equalise path length?\n",
    "The angular resolution of a telescope is the smallest angle between objects that can be visibly resolved and is proportional to the telescope diameter. Although, when using two telescopes together, the angular resolution is set by the distance between the telescopes and not the sizes of the individual telescopes. This means two telescopes that are distance $D$ apart have the same resolving capability (but not light collecting capability) as a larger continuous telescope of diameter $D$. To get the telescope joining benefits, the light in both branches must have travelled the same distance down to the tenths of wavelength to see an image (due to finite coherence lengths, this is explainined clearly in any optics textbook). \n",
    "\n",
    "The first telescope to take advantage of this effect was the Michelson stellar interferometer in 1920 when it was set up on Mount Wilson, California to image the star Betelgeuse. Today the Centre for High Angular Resolution Astronomy (CHARA) array sits on Mount Wilson. CHARA consists of six 1m telescopes arranged in a Y-shape (see figure above) with baseline distance distances between telescopes ranging from 34m to 330m. It is possible to use measurements from the CHARA array to find the positions of the telescopes relative to each other and find whether there has been significant movement of the telescopes between different dates.\n",
    "\n",
    "\n",
    "**The physics of this problem is unimportant to understanding the analysis. All you need to know is that there is an equation describing the path difference between two different telescopes. All measurements have a path length difference ~0. This path length difference is a balance of the light travelling different distances before capture due to the position of the star and different distances after capture due to mirrors.**\n",
    "\n",
    "\n",
    "<img src=\"https://www.chara.gsu.edu/files/Tutorials/interferometer_basic.png\"  width=\"500\">\n",
    "\n",
    "$$\\text{optical path difference}= \\hat{\\pmb{S}} \\cdot (\\pmb{r}_1 - \\pmb{r}_2) + d_1 - d_2$$\n",
    "\n",
    "Where $d_i = \\text{CART}_i + \\text{POP}_i$ is the path of the $i$th after being captured by the telescope (i.e. the distance due to the mirrors). The POPs are fixed mirrors that add a constant distance and the CARTs are contstantly moving to try and equalise the path difference.\n",
    "\n",
    "So when the optical path difference is zero we can sub in the expression for $d_i$ and get the equation (full derivation for this equation can be found in the report):\n",
    "\n",
    "$$\\text{CART}_2 - \\text{CART}_1 = \\hat{\\pmb{S}} \\cdot (\\pmb{r}_1 - \\pmb{r}_2) + \\text{POP}_1 - \\text{POP}_2$$\n",
    "\n",
    "**It is important to understand that the only data taken from the measurements is the positions of the mirrors and angle of the star i.e.  no data on the brightness etc etc** \n",
    "\n",
    "### Matrix equation for a set of measures\n",
    "\n",
    "$$y = X \\beta$$\n",
    "\n",
    "Each measurement gives us a linear equation - these equations can be represented by a single matrix equation. $y$ is a vector of the difference in the cart values i.e. the LHS, $\\beta$ is a vector of the model parameters (as list of values that the measurements can take), this is the positions of the telescopes and the POP settings used and $X$ is the design matrix (i.e. the coefficients to equations for each measurement).\n",
    "\n",
    "## Mathematics in depth (can be skipped)\n",
    "\n",
    "<img src=\"figures/overdetermined-example.png\"  width=\"500\">\n",
    "\n",
    "For large data sets, the matrix equation $y = X\\beta$ often has more measurements/equations than model parameters/unknowns, i.e. the design matrix is “skinny”. These problems are known as overdetermined. The model parameter space of an overdetermined system can be seen in the figure above, where there are 3 equations for 2 unknowns. There is not a single point in parameter space that satisfies all three equations, i.e $y - X \\beta \\neq 0$ for all $\\beta$. This is equivalent to saying no inverse of $X$ exist (inverses only exist for squares matrices), if one did exist $X^{-1}y = \\beta$  and so $y - X(X^{-1}y) = 0$. $y - X\\beta$ is the residual vector and is the difference between the data $y$ and the model prediction $X\\beta$.\n",
    "\n",
    "The “best-fit” solution is found via minimising the 2-norm of the residuals, $\\|y - Xb \\|_2$, with respect to $\\beta$. The minimum can be found by assuming a minimum norm value at $\\hat{b}$ and taking small perturbations around this point (see appendix A). This gives the solution $X^TX\\hat{b} = A^T y$ (this is known as the normal matrix equation) which can rearranged to give the expression an $\\hat{\\beta}$, as seen in the equation below. $A^+$ is known as the Moore-Penrose inverse or pseudoinverse and is a way of generalising the matrix inverse for non-square matrices. It can be used to find $\\hat{b}$. \n",
    "\n",
    "$$\\hat{\\beta} = (A^T A)^{-1} A^T y = A^+ y$$\n",
    "\n",
    "By being the solution to minimising the 2-norm, the pseudoinverse is the solution that minimises the sum of squares of the residuals and is know as ordinary least-squares (OLS). OLS is preferred over other loss functions as it maximises likelihood, though it is very sensitive to outliers so cleaning data is especially important. In the example of the $3 \\times 2$  overdetermined matrix, the pseudoinverse gives the point, $\\hat{b}$,  which is the OLS from all the solution points and is shown as red dot on the graph. In this project, the Moore-Penrose pseudoinverse was used to find the model parameters. \n",
    "\n",
    "**The important thing to takeaway here is that for datasets that are overdetermined, i.e have more datapoints than model parameters, a pseudoinverse can be constructed that is equivilant to least squares regression linear regression!**\n",
    "\n",
    "In this problem, our model parameters are the different columns of the design matrix i.e the 15 positions of the telescopes and the values of the pop settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a975a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the most important packages for data science!\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14aac05",
   "metadata": {},
   "source": [
    "## Preprocessing (a.k.a cleaning)\n",
    "\n",
    "First of all it is important to have a look at the data and see what is looks like. Ensure that there are no errors or things that could be changed to improve experience. In this example we will be using the data set for the night of April 7th 2019. NB that the elevation and azimuth are the direction of the star from the telecopes in [horizontal coordinates](https://en.wikipedia.org/wiki/Horizontal_coordinate_system#:~:text=The%20horizontal%20coordinate%20system%20is,%2Dazimuth%20system%2C%20among%20others.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fb0b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utc</th>\n",
       "      <th>star</th>\n",
       "      <th>elevation</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>tel_1</th>\n",
       "      <th>tel_2</th>\n",
       "      <th>pop_1</th>\n",
       "      <th>pop_2</th>\n",
       "      <th>cart_1</th>\n",
       "      <th>cart_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-07T03:18:25.000</td>\n",
       "      <td>#93396</td>\n",
       "      <td>282.904832</td>\n",
       "      <td>73.303565</td>\n",
       "      <td>W1</td>\n",
       "      <td>W2</td>\n",
       "      <td>P3B3</td>\n",
       "      <td>P5B2</td>\n",
       "      <td>62.585687</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-07T03:18:25.000</td>\n",
       "      <td>#93396</td>\n",
       "      <td>282.904832</td>\n",
       "      <td>73.303565</td>\n",
       "      <td>S2</td>\n",
       "      <td>W1</td>\n",
       "      <td>P2B4</td>\n",
       "      <td>P3B3</td>\n",
       "      <td>39.085558</td>\n",
       "      <td>62.585687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-07T03:18:29.000</td>\n",
       "      <td>#93396</td>\n",
       "      <td>282.903948</td>\n",
       "      <td>73.290095</td>\n",
       "      <td>W1</td>\n",
       "      <td>W2</td>\n",
       "      <td>P3B3</td>\n",
       "      <td>P5B2</td>\n",
       "      <td>62.610570</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-07T03:18:34.000</td>\n",
       "      <td>#93396</td>\n",
       "      <td>282.902857</td>\n",
       "      <td>73.273259</td>\n",
       "      <td>W1</td>\n",
       "      <td>W2</td>\n",
       "      <td>P3B3</td>\n",
       "      <td>P5B2</td>\n",
       "      <td>62.641690</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-07T03:32:01.000</td>\n",
       "      <td>#93396</td>\n",
       "      <td>282.893761</td>\n",
       "      <td>70.555509</td>\n",
       "      <td>S2</td>\n",
       "      <td>W1</td>\n",
       "      <td>P2B4</td>\n",
       "      <td>P3B3</td>\n",
       "      <td>43.169167</td>\n",
       "      <td>76.216268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       utc    star   elevation    azimuth tel_1 tel_2 pop_1  \\\n",
       "0  2019-04-07T03:18:25.000  #93396  282.904832  73.303565    W1    W2  P3B3   \n",
       "1  2019-04-07T03:18:25.000  #93396  282.904832  73.303565    S2    W1  P2B4   \n",
       "2  2019-04-07T03:18:29.000  #93396  282.903948  73.290095    W1    W2  P3B3   \n",
       "3  2019-04-07T03:18:34.000  #93396  282.902857  73.273259    W1    W2  P3B3   \n",
       "4  2019-04-07T03:32:01.000  #93396  282.893761  70.555509    S2    W1  P2B4   \n",
       "\n",
       "  pop_2     cart_1     cart_2  \n",
       "0  P5B2  62.585687  80.000000  \n",
       "1  P3B3  39.085558  62.585687  \n",
       "2  P5B2  62.610570  80.000000  \n",
       "3  P5B2  62.641690  80.000000  \n",
       "4  P3B3  43.169167  76.216268  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/original_2019_04_07.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db04c066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2034 measurements on this night\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4193a763",
   "metadata": {},
   "source": [
    "### Things to change \n",
    "- UTC text data into a form that is easier to search by \n",
    "- Swap elevation and azimuth as these were given the wrong way around\n",
    "- Swap from degrees to radians as radians are the default angle unit for trig functions in `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92bbc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utc</th>\n",
       "      <th>star</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>elevation</th>\n",
       "      <th>tel_1</th>\n",
       "      <th>tel_2</th>\n",
       "      <th>pop_1</th>\n",
       "      <th>pop_2</th>\n",
       "      <th>cart_1</th>\n",
       "      <th>cart_2</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-07T03:18:25.000</td>\n",
       "      <td>#93396</td>\n",
       "      <td>4.937621</td>\n",
       "      <td>1.279389</td>\n",
       "      <td>W1</td>\n",
       "      <td>W2</td>\n",
       "      <td>P3B3</td>\n",
       "      <td>P5B2</td>\n",
       "      <td>62.585687</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-07T03:18:25.000</td>\n",
       "      <td>#93396</td>\n",
       "      <td>4.937621</td>\n",
       "      <td>1.279389</td>\n",
       "      <td>S2</td>\n",
       "      <td>W1</td>\n",
       "      <td>P2B4</td>\n",
       "      <td>P3B3</td>\n",
       "      <td>39.085558</td>\n",
       "      <td>62.585687</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-07T03:18:29.000</td>\n",
       "      <td>#93396</td>\n",
       "      <td>4.937605</td>\n",
       "      <td>1.279153</td>\n",
       "      <td>W1</td>\n",
       "      <td>W2</td>\n",
       "      <td>P3B3</td>\n",
       "      <td>P5B2</td>\n",
       "      <td>62.610570</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-07T03:18:34.000</td>\n",
       "      <td>#93396</td>\n",
       "      <td>4.937586</td>\n",
       "      <td>1.278860</td>\n",
       "      <td>W1</td>\n",
       "      <td>W2</td>\n",
       "      <td>P3B3</td>\n",
       "      <td>P5B2</td>\n",
       "      <td>62.641690</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-07T03:32:01.000</td>\n",
       "      <td>#93396</td>\n",
       "      <td>4.937428</td>\n",
       "      <td>1.231426</td>\n",
       "      <td>S2</td>\n",
       "      <td>W1</td>\n",
       "      <td>P2B4</td>\n",
       "      <td>P3B3</td>\n",
       "      <td>43.169167</td>\n",
       "      <td>76.216268</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       utc    star   azimuth  elevation tel_1 tel_2 pop_1  \\\n",
       "0  2019-04-07T03:18:25.000  #93396  4.937621   1.279389    W1    W2  P3B3   \n",
       "1  2019-04-07T03:18:25.000  #93396  4.937621   1.279389    S2    W1  P2B4   \n",
       "2  2019-04-07T03:18:29.000  #93396  4.937605   1.279153    W1    W2  P3B3   \n",
       "3  2019-04-07T03:18:34.000  #93396  4.937586   1.278860    W1    W2  P3B3   \n",
       "4  2019-04-07T03:32:01.000  #93396  4.937428   1.231426    S2    W1  P2B4   \n",
       "\n",
       "  pop_2     cart_1     cart_2  year  month  day  dayofyear  \n",
       "0  P5B2  62.585687  80.000000  2019      4    7         97  \n",
       "1  P3B3  39.085558  62.585687  2019      4    7         97  \n",
       "2  P5B2  62.610570  80.000000  2019      4    7         97  \n",
       "3  P5B2  62.641690  80.000000  2019      4    7         97  \n",
       "4  P3B3  43.169167  76.216268  2019      4    7         97  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create seperate columns for year, month, day and dayofyear\n",
    "dates = pd.to_datetime(df.utc)\n",
    "df[\"year\"] = [date.year for date in dates]\n",
    "df[\"month\"] = [date.month for date in dates]\n",
    "df[\"day\"] = [date.day for date in dates]\n",
    "df[\"month\"] = [date.month for date in dates]\n",
    "df[\"dayofyear\"] = [date.day_of_year for date in dates]\n",
    "\n",
    "# need to swap the elevation and azimuth \n",
    "df = df.rename(columns={\"elevation\": \"azimuth\", \"azimuth\": \"elevation\"})\n",
    "\n",
    "# change to radians\n",
    "df[\"azimuth\"] = df[\"azimuth\"] * 2 * np.pi / 360\n",
    "df[\"elevation\"] = df[\"elevation\"] * 2 * np.pi / 360\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84149bef",
   "metadata": {},
   "source": [
    "**The preprocessing for all the other datasets has been complete so you don't need to do it again!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73386c52",
   "metadata": {},
   "source": [
    "## Creating the design matrix\n",
    "\n",
    "### Shape \n",
    "We want as many rows as number of measurements but how many columns do we want? \n",
    "\n",
    "To represent categorical data in a matrix a model parameter is needed for each category, this is known as one-hot encoding. With six telescopes whose positions can only be known relative to each other there are 15 model parameters for telescope positions $(x, y, z)$ as one telescope, which can be arbitrarily picked (here it is E1), is placed at the origin (telescope positions can only be found relative to eachother). There can be a minimum of six POP parameters when each telescope only used one POP settings and up to 180 when all six telescopes use all 30 available POP settings. Note ‘PXBY’ on one telescope is not the same when used on another telescope. Once the number of unique POP settings is found an empty design matrix can be initialised with shape (data points, 15 + unique POPs).\n",
    "\n",
    "One-hot encoding works by putting a $1$ for parameters that are present in a measurement and a $0$ for parameters that aren't present so that in the matrix multiplication. In the equation below for the $i$th measurement only the correct telescopes, POP and CART settings are present. \n",
    "\n",
    "$$y_i = X_{ij} \\beta_j = \\hat{\\textbf{S}}_i \\cdot (\\pmb{r}_{i,1} - \\pmb{r}_{i,2}) + \\text{POP}_{i,1} - \\text{POP}_{i,2}$$\n",
    "\n",
    "The values of the star vector are also converted from horizontal coordinates to Cartesian coordinates and are then dotted with the positions of the telescopes. \n",
    "\n",
    "### the important thing to understand is that we've turned qualitative categorical data into a quantiative equations that make up the rows of a matrix, this can be inverted to find the model parameters using the pseudoinverse which was derived earlier\n",
    "\n",
    "This following will populate a design matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f4d1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first need to convert from horizontal coordinates to normal coordinates \n",
    "# provide link and a sketch|\n",
    "theta = df.elevation\n",
    "phi = df.azimuth\n",
    "S = np.array(\n",
    "    [np.cos(theta) * np.sin(phi), np.cos(theta) * np.cos(phi), np.sin(theta)]\n",
    ").T\n",
    "\n",
    "# use transpose `.T` to ensure the S vector is the correct shape\n",
    "# finding the correct shape is often found by trial and error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bce1cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 34)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telescopes = [\"E1\", \"W2\", \"W1\", \"S2\", \"S1\", \"E2\"]\n",
    "\n",
    "tot_unique_pops = []\n",
    "width = 15 # 3 spatial coordinates for 5 non-zero telescope\n",
    "\n",
    "for telescope in telescopes:\n",
    "\n",
    "    # for each telescope find the number of unique pop settings \n",
    "    pop_tel_1 = df[df.tel_1 == telescope].pop_1\n",
    "    pop_tel_2 = df[df.tel_2 == telescope].pop_2 \n",
    "    tel_1_unique_pops = np.unique(pop_tel_2)\n",
    "    tel_2_unique_pops = np.unique(pop_tel_1)\n",
    "    \n",
    "    \n",
    "    tel_unique_pops = np.union1d(tel_1_unique_pops, tel_2_unique_pops)\n",
    "    tot_unique_pops.append(tel_unique_pops)\n",
    "    \n",
    "    # increment the width by the number of unique pop settings for ea. telescope\n",
    "    width += len(tel_unique_pops)\n",
    "\n",
    "# with the correct shape it is possible to instantiate the numpy array of the correct dimensions\n",
    "design_mat = np.zeros((len(df), width))\n",
    "\n",
    "design_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39221b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "\n",
    "for i, telescope in enumerate(telescopes):\n",
    "\n",
    "    # for ea. new telescope must jump 3 places for (x, y, z)\n",
    "\n",
    "    if telescope != \"E1\":  # keep 'E1' as the zero point\n",
    "        \n",
    "        # have the one-hot encoding for the telescopes (apart from E1 as this is at the origin)\n",
    "        # then dot with the star vector (this takes advantage of numpy array vectorisation)\n",
    "    \n",
    "        design_mat[:, 3 * i - 3 : 3 + 3 * i - 3] += S * np.where(\n",
    "            df[\"tel_1\"] == telescope, 1, 0\n",
    "        ).reshape(-1, 1)\n",
    "        design_mat[:, 3 * i - 3 : 3 + 3 * i - 3] -= S * np.where(\n",
    "            df[\"tel_2\"] == telescope, 1, 0\n",
    "        ).reshape(-1, 1)\n",
    "\n",
    "    for pop in tot_unique_pops[i]:\n",
    "        \n",
    "        # add the one-hot encoding for the pop settings\n",
    "        # +1 for POP 1 and -1 for POP 2 \n",
    "\n",
    "        design_mat[:, 15 + k] += np.where(\n",
    "            (df[\"pop_1\"] == pop) & (df[\"tel_1\"] == telescope), 1, 0\n",
    "        )  # add when it is tel_1\n",
    "        design_mat[:, 15 + k] -= np.where(\n",
    "            (df[\"pop_2\"] == pop) & (df[\"tel_2\"] == telescope), 1, 0\n",
    "        )  # subtract when it is the tel_2\n",
    "\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64825390",
   "metadata": {},
   "source": [
    "## Comparison to the maths \n",
    "\n",
    "The original matrix equation was $y = X \\beta$. Here we have the created the y vector from the difference between the two cart positions and the design matrix which we have populated using one-hot encoding. `numpy` has the pseudoinverse (pinv) function already written leading for a speedy inversion so that we can find the model parameters i.e. the $\\beta$ vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66383ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([194.43260791, 106.59897763,  -6.37520967, 300.40862676,\n",
       "        89.60984578,   4.88053282, 131.08378955, 272.35384145,\n",
       "        -6.54767727, 125.33690067, 305.93267805,  -5.90805154,\n",
       "        54.94397029,  36.20990241,  -3.10685717])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"cart_2\"].values - df[\"cart_1\"].values\n",
    "pinv = np.linalg.pinv(design_mat)\n",
    "beta = pinv @ y \n",
    "\n",
    "beta[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044db46",
   "metadata": {},
   "source": [
    "Below is the table of the original results given in the 2005 paper. Since E1 is the zero point in our data focus on the baselines where it starts or finishes with E1 - it matches pretty well!\n",
    "\n",
    "| Telescopes | East (m) | North (m) | Height (m) | Baseline (m) |\n",
    "|------------|----------|-----------|------------|--------------|\n",
    "| S2-S1      | -5.747   | 33.579    | 0.640      | 34.073       |\n",
    "| E2-E1      | -54.943  | -36.210   | 3.108      | 65.876       |\n",
    "| W2-W1      | 105.976  | -16.989   | 11.255     | 107.918      |\n",
    "| W2-E2      | -139.489 | -70.388   | 3.268      | 156.277      |\n",
    "| W2-S2      | -63.349  | 165.755   | -0.173     | 177.448      |\n",
    "| W2-S1      | -69.096  | 199.334   | 0.467      | 210.970      |\n",
    "| W2-E1      | -194.432 | -106.598  | 6.375      | 221.828      |\n",
    "| E2-S2      | 76.140   | 236.143   | -3.441     | 248.139      |\n",
    "| W1-S2      | -169.325 | 182.744   | -11.428    | 249.393      |\n",
    "| W1-E2      | -245.465 | -53.399   | -7.987     | 251.333      |\n",
    "| W1-S1      | -175.072 | 216.323   | -10.788    | 278.500      |\n",
    "| E2-S1      | 70.393   | 269.722   | -2.801     | 278.77       |\n",
    "| E1-S2      | 131.083  | 272.353   | -6.548     | 302.328      |\n",
    "| W1-E1      | -300.408 | -89.609   | -4.88      | 313.526      |\n",
    "| E1-S1      | 125.337  | 305.932   | -5.908     | 330.664      |\n",
    "\n",
    "\n",
    "As discussed earlier, this is just linear regression! although this is trivial to do in libraries such as `sklearn` you now understand the inner workings of the mathematics behind linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ba2a2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([194.43261114, 106.59898649,  -6.37508527, 300.40865911,\n",
       "        89.609894  ,   4.88057381, 131.08380509, 272.35393989,\n",
       "        -6.54766819, 125.33696951, 305.93276828,  -5.90799966,\n",
       "        54.94395888,  36.20983782,  -3.10685763])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model \n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(design_mat, y).coef_[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb6b95d",
   "metadata": {},
   "source": [
    "I understand that this missed much of the mathematical and physical rigour which is hopefully found in the full [report](projectE-hs723.pdf). This project has huge scope to look at rich areas of linear algebra such as the null spaces of different design matrices - I really hope I can revisit it in the future. \n",
    "\n",
    "Thank you if you made it this far! If you've got any feedback/questions a message on LinkedIn would be great."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
